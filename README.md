Data Cleaning & Exploratory Analysis on Air Quality Data ðŸŒ¿
This week, I worked on an insightful data project focusing on air quality measurements across different geographies and time periods. Hereâ€™s a snapshot of what I did:

Data Cleaning
Handled Missing Values:

Numeric fields were converted to appropriate formats and missing values filled with mean values.

Categorical fields like Geo Place Name and Measure Info were filled with their mode or assigned "Unknown" where necessary.

Ensured Consistency:

Date fields were converted into a standardized datetime format.

Cleaned datasets were saved for future use.

Exploratory Data Analysis (EDA)
Statistical Overview: Generated descriptive statistics and dataset summaries.

Insights Uncovered:

Identified top contributing geographies and their corresponding maximum data values.

Analyzed average data values by different measures.

Explored trends over time and the distribution of data across locations.

Visualizations Created
Histograms and KDE plots for value distribution.

Boxplots and violin plots by measure categories.

Time-series trends of air quality over the years.

Correlation heatmaps for numerical relationships.

Bar charts, count plots, and pie charts for categorical breakdowns.

Outcome
Cleaned dataset saved as Air_Quality_Cleaned.csv.

Transformed dataset with enriched analysis saved as Air_Quality_Transformed.csv.

This project was a great opportunity to dive deep into data wrangling, visualization, and trend analysis using Python libraries like Pandas, Matplotlib, Seaborn, and NumPy.

Tech Stack: Python, Pandas, NumPy, Seaborn, Matplotlib
